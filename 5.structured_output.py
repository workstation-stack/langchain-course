# Module 5: Structured Output
# This module introduces structured output using Pydantic models, which ensures that the agent's responses follow a specific schema.
# Structured output is important because it makes the agent's responses predictable and easier to process programmatically.
# Here, we define a schema (`AgentResponse`) that includes an answer and a list of sources, ensuring the output is well-structured.
# The module demonstrates how to use LangChain's `create_agent` function with a `return_format` parameter to enforce this schema.
# Key Difference: This module uses the newer `create_agent` function, which simplifies the integration of structured output.
# For example, it can search for job postings and return the results in a well-defined format with URLs.

from typing import List

from pydantic import BaseModel, Field
from dotenv import load_dotenv

load_dotenv()
from langchain.agents import create_agent
from langchain.tools import tool
from langchain_openai import ChatOpenAI
from langchain_ollama import ChatOllama
from langchain_core.messages import HumanMessage
from langchain_tavily import TavilySearch

class Source(BaseModel):
    """Schema for a source used by agent."""
    url: str = Field(description="The URL of the source.")

class AgentResponse(BaseModel):
    """Schema for the agent's response."""
    answer: str = Field(description="The final answer generated by the agent.")
    sources: List[Source] = Field(description="List of sources used to generate the answer.")

llm = ChatOpenAI()
# llm = ChatOllama(model="gemma3:270m", temperature=0)
tools = [TavilySearch()]
agent = create_agent(model=llm, tools=tools, return_format=AgentResponse)

def main():
    print("Hello from search_agent!")
    result_2 = agent.invoke({"messages": HumanMessage(content="search for 3 job postings for an ai engineer using langchain in Hyderabad on linkedin and list the results")})
    print(result_2)


        
    
if __name__ == "__main__":
    main()